{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do the imports, so that we write less code\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from PIL import Image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hd/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Prepare and load the data for analysis\n",
    "mat = scipy.io.loadmat('2013MT60597.mat')\n",
    "raw_data = mat['data_image']\n",
    "target = mat['data_labels']\n",
    "\n",
    "data = scale(raw_data)\n",
    "true_labels = target.flatten()\n",
    "n_samples, n_features = data.shape\n",
    "n_digits = len(np.unique(target))\n",
    "# print(n_digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 6, 2, 5], dtype=int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # run K-Means clustering on \n",
    "# model = KMeans(init='k-means++', n_clusters=n_digits, n_init=10);\n",
    "# model.fit_predict(data)\n",
    "model_raw_data = KMeans(init='k-means++', n_clusters=10, n_init=10)\n",
    "model_raw_data.fit_predict(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getPredictions(labels):\n",
    "    # store the cluster indexes assigned by the model in an array\n",
    "    result = labels\n",
    "    # build matrix whose ith row corresponds to ith cluster_index\n",
    "    # matrix[i][j] denotes no. of samples of true_label j assigned to cluster i\n",
    "    matrix = np.zeros((5,10))\n",
    "    for i in range(1,n_samples):\n",
    "        matrix[result[i]][true_labels[i]] += 1\n",
    "    # take argmax of each row to assign the label to that cluster\n",
    "    cluster_label = np.zeros(5)\n",
    "    for i in range(0,5):\n",
    "        cluster_label[i] = np.argmax(matrix[i,:])\n",
    "    # after assigning the cluster labels, get the label predicted by the model using the cluster index assigned      \n",
    "    predicted = np.zeros(n_samples)\n",
    "    for i in range(1,n_samples):\n",
    "        predicted[i] = cluster_label[result[i]]\n",
    "    return predicted, cluster_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the no. of misclassified samples\n",
    "def getAccuray(true_labels,predicted_labels,samples):\n",
    "    accuracy = 0.0;\n",
    "    for i in range(1,samples):\n",
    "        if(true_labels[i] == predicted_labels[i]):\n",
    "            accuracy +=1\n",
    "    return accuracy/samples\n",
    "def getImage(x):\n",
    "    img =  Image.fromarray(255 - (x.reshape(28, 28)).astype('uint8'))\n",
    "#     plt.imshow(img,cmap='Greys_r')\n",
    "#     plt.show()\n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5795"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted_scaled_data, cluster_label_scaled_data = getPredictions(model.labels_)\n",
    "predicted_raw_data, cluster_label_raw_data = getPredictions(model_raw_data.labels_)\n",
    "getAccuray(true_labels,predicted_raw_data,n_samples)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    name = cluster_label_raw_data[i]    \n",
    "    name = str(name)+ str(i)  + \"_.png\"   \n",
    "    img = getImage(model_raw_data.cluster_centers_[i])\n",
    "    img.save(name)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations on raw data\n",
    "### K = 10\n",
    "* The accuracy achieved is 57%. Though it fluctuates a little bit every time due to the random initilizations. \n",
    "* The cluster centers are saved in a separate folder. Analysis reveals that 0 and 9 are assigned the same label. This might be due to the similarity in their bitmap representations. \n",
    "* Also we see that 4 and 5 have the same cluster center. So our model cannot distinguish between images of 4 and 5 correctly.\n",
    "* Also , we see that the cluster centers of 4 and 7 have a bit of resemblance to 9 in them. This might be because of the similarity in their structure.\n",
    "* We see that the class 0 has two cluster centers. My interpretation is that in reality 0 has a single cluster center, but due to highly similar resemblance to 9, it has occupied its cluster center.\n",
    "\n",
    "### K = 5\n",
    "* The accuracy achieved is 43%, which varies a little bit every time.\n",
    "* The cluster centers are saved in a separate folder. Analysis reveals that the cluster center of 0 is exceptionaly well captured, but all the other cluster centers are mixed and highly overlap with different digits.\n",
    "* Observations reveals that cluster centers of 1 ,5 and 7 are combined. Similarly centers of 3, 8 and 9,7 are combined\n",
    "* So, in this case, our cluster centers do not make much sense.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U, s, V = np.linalg.svd(data)\n",
    "\n",
    "\n",
    "total_variance = sum(s)\n",
    "total_variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, n_components=0.9, whiten=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.9)\n",
    "pca.fit(raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90021308635218056"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data = pca.transform(raw_data)\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def getResidualVariance():\n",
    "    variance_residual = np.zeros(pca.n_components_)\n",
    "    var_explained = pca.explained_variance_ratio_\n",
    "    temp = 0;\n",
    "    for i in range(0,pca.n_components_):\n",
    "        temp += var_explained[i]\n",
    "        variance_residual[i] = 1 -temp    \n",
    "    return variance_residual\n",
    "        \n",
    "\n",
    "pca.n_components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "residual_variance = getResidualVariance()\n",
    "X = np.linspace(0, pca.n_components_,pca.n_components_)\n",
    "plt.xlabel('No. of Principal Components Taken')\n",
    "plt.ylabel('Residual Variance')\n",
    "plt.title('Residual Variance Plot')\n",
    "# plt.xticks(np.linspace(0, pca.n_components_,1), X)\n",
    "plt.plot(X, residual_variance,'ro')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 9, 2, ..., 8, 1, 7], dtype=int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transformed_data = KMeans(init='k-means++', n_clusters=10, n_init=10)\n",
    "model_transformed_data.fit_predict(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5735"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_tranformed_data, cluster_label_transformed_data = getPredictions(model_transformed_data.labels_)\n",
    "getAccuray(true_labels,predicted_tranformed_data,n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_data = pca.inverse_transform(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.441"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KMeans(init='k-means++', n_clusters=5, n_init=10)\n",
    "model.fit_predict(original_data)\n",
    "predicted_data, cluster_label_data = getPredictions(model.labels_)\n",
    "getAccuray(true_labels,predicted_data,n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    name = cluster_label_data[i]    \n",
    "    name = str(name)+ str(i)  + \"_.png\"   \n",
    "    img = getImage(model.cluster_centers_[i])\n",
    "    img.save(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations for reduced data\n",
    "### K = 10\n",
    "\n",
    "* The accuracy achieved is 57.9%, which is only 0.9% more than the previous case. So we can say that running PCA doesnot offer much advantage in this scenario.\n",
    "* We project the data back to its original space to see that cluster centers we obtain of run the k means on this space. \n",
    "* We see that the cluster centers of 4 and 7 have a bit of resemblance to 9 in them. This might be because of the similarity in their structure.\n",
    "* We see that the class 7 has two cluster centers. My interpretation is that in reality 7 has a single cluster center, but due to highly similar resemblance to 9, it has occupied its cluster center, and both the cluster centers have high resemblance to both the digits.\n",
    "\n",
    "### K = 5\n",
    "\n",
    "* The accuracy achieved is 43%, which varies a little bit every time.\n",
    "* The cluster centers are saved in a separate folder. Analysis reveals that the cluster center of 0 is exceptionaly well captured, but all the other cluster centers are mixed and highly overlap with different digits.\n",
    "* The cluster center labelled 1 has a high resemblance of 5 in it\n",
    "* Similarly cluster center labelled 3 has a high resemblance of 8 in it, same for the case of 9, which resembles 7 to a high extent\n",
    "\n",
    "We see that using PCA doesnot offer much advantage. This might be due to the fact the for capturing 90% of the variance, we need 82 dimensions . Now 82 dimensions in itself is a very high dimensional space and the curse of dimensionality is playing its part there too. So we donot get a significant advantage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
