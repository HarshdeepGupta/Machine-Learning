{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do the imports, so that we write less code\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from PIL import Image\n",
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare and load the data for analysis\n",
    "mat = scipy.io.loadmat('2013MT60597.mat')\n",
    "raw_data = mat['data_image']\n",
    "target = mat['data_labels']\n",
    "true_labels = target.flatten()\n",
    "n_samples, n_features = raw_data.shape\n",
    "n_digits = len(np.unique(target))\n",
    "k = n_digits\n",
    "# print(n_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compress the data using PCA\n",
    "pca = PCA(n_components=20)\n",
    "pca.fit(raw_data)\n",
    "transformed_data = pca.transform(raw_data)\n",
    "transformed_data = scale(transformed_data)\n",
    "n_samples, n_features = transformed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 9, 3, 1], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run Kmeans to initialize the centers\n",
    "model = KMeans(init='k-means++', n_clusters=n_digits, n_init=10);\n",
    "model.fit_predict(transformed_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Global variables, which the E-step and M_step will modify \n",
    "\n",
    "w_s = np.zeros((k,n_samples)) \n",
    "mu_s = np.zeros((k, n_features))\n",
    "sigma_s = np.zeros((k,n_features,n_features))\n",
    "phi_s = np.zeros(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Kmeans_init(): \n",
    "    # return mu_s, sigma_s and phi_s\n",
    "    mu_s = model.cluster_centers_\n",
    "    phi_s = np.random.rand(k)\n",
    "    phi_s /= phi_s.sum()\n",
    "#     sigma_s = np.random.rand(k,n_features,n_features)*10\n",
    "    for i in range(k):\n",
    "        sigma_s[i] = np.eye(n_features)\n",
    "    return mu_s,sigma_s,phi_s\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def runGMM():\n",
    "    DEBUG = False\n",
    "    likelihood_old = 0.0\n",
    "    likelihood_new = 0.0    \n",
    "    likelihood_array = []\n",
    "    \n",
    "    # Global variables, which the E-step and M_step will modify \n",
    "\n",
    "    w_s = np.zeros((k,n_samples)) \n",
    "    mu_s = np.zeros((k, n_features))\n",
    "    sigma_s = np.zeros((k,n_features,n_features))\n",
    "    phi_s = np.zeros(k)\n",
    "    \n",
    "    #initialize mu_s, sigma_s and phi_s\n",
    "    # keep mu_s obtained from the kmeans method\n",
    "    mu_s = model.cluster_centers_\n",
    "    phi_s = np.random.rand(k)\n",
    "    phi_s /= phi_s.sum()\n",
    "    for i in range(k):\n",
    "        sigma_s[i] = np.eye(n_features)\n",
    "#################################\n",
    "#     #Some Testing\n",
    "#     for j in range(10):\n",
    "#         mvn_i = mvn(mu_s[j],sigma_s[j])\n",
    "#         print(mvn_i.logpdf(transformed_data[9]).T)\n",
    "# #         w_s[i][j] = mvn_i.pdf(transformed_data[j])*phi_s[i]\n",
    "\n",
    "################################\n",
    "\n",
    "#     run the loop at max 300 times\n",
    "    for loop in range(100): \n",
    "        print(\"Running iteration \" )\n",
    "        print(loop+1)\n",
    "        # E step\n",
    "\n",
    "        for i in range(k):\n",
    "            mvn_i = mvn(mu_s[i],sigma_s[i])\n",
    "            for j in range(n_samples):\n",
    "                w_s[i][j] = mvn_i.pdf(transformed_data[j])*phi_s[i]\n",
    "        sums = w_s.sum(0)\n",
    "        for i in range(n_samples):\n",
    "            w_s[:,i] /= sums[i]\n",
    "        if DEBUG:\n",
    "            print(\"Printing W_s\")\n",
    "            print(w_s.sum(0))\n",
    "        \n",
    "\n",
    "\n",
    "        # M step\n",
    "        #update the phi_s\n",
    "        for i in range(k):\n",
    "            for j in range(n_samples):\n",
    "                phi_s[i] += w_s[i][j]\n",
    "        phi_s /= n_samples\n",
    "\n",
    "        #update the mu_s\n",
    "        mu_s = np.dot(w_s,transformed_data)\n",
    "        sums = w_s.sum(1)\n",
    "        for i in range(k):\n",
    "            mu_s[i] /= sums[i]\n",
    "        if DEBUG:\n",
    "            print(\"Printing Mu_s\")\n",
    "            print(mu_s)\n",
    "        \n",
    "    \n",
    "        #update the sigma_s\n",
    "        for j in range(k):\n",
    "            for i in range(n_samples):\n",
    "                y = (transformed_data[i] - mu_s[j]).reshape(n_features,1)\n",
    "                sigma_s[j] += np.dot(y,y.T) * w_s[j][i]\n",
    "            sigma_s[j] /= w_s[j].sum()\n",
    "            #Reassign if determinant = 0\n",
    "            if np.linalg.det(sigma_s[j]) <= 1e-15:\n",
    "                print(\"reassigned on iteration \",loop,\"matrix\",j)\n",
    "                sigma_s[j] = np.eye(n_features)\n",
    "                \n",
    "        if DEBUG:\n",
    "            print(\"Printing Sigmas_s\")\n",
    "            print(sigma_s)\n",
    "        \n",
    "\n",
    "        # update the LogLikelihood every step        \n",
    "\n",
    "        likelihood_new = 0.0\n",
    "        for i in range(n_samples):\n",
    "            temp = 0\n",
    "            for j in range(k):\n",
    "                temp +=  mvn(mu_s[j], sigma_s[j]).pdf(transformed_data[i]) * phi_s[j] \n",
    "#                     print(i,j,mvn(mu_s[j], sigma_s[j]).pdf(transformed_data[i]) * phi_s[j] )\n",
    "            likelihood_new += np.log(temp)\n",
    "        likelihood_array.append(likelihood_old)\n",
    "        print(likelihood_new)\n",
    "\n",
    "\n",
    "        if np.abs(likelihood_old -likelihood_new) < 1:\n",
    "            print(\"likelihood reached a minima\")\n",
    "            break\n",
    "        likelihood_old = likelihood_new\n",
    "    return w_s, likelihood_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "result_w_s , likelihood_array = runGMM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPredictions(result_w_s):\n",
    "   \n",
    "    # take argmax of columns of result_w_s matrix and take transpose of it so that we get a simple array\n",
    "\n",
    "    result = np.argmax(result_w_s, axis=0)\n",
    "#     result = np.flatten(result)\n",
    "    # build matrix whose ith row corresponds to ith cluster_index\n",
    "    # matrix[i][j] denotes no. of samples of true_label j assigned to cluster i\n",
    "    matrix = np.zeros((10,10))\n",
    "    for i in range(n_samples):\n",
    "        matrix[result[i]][true_labels[i]] += 1\n",
    "    # take argmax of each row to assign the label to that cluster\n",
    "    cluster_label = np.zeros(10)\n",
    "    for i in range(k):\n",
    "        cluster_label[i] = np.argmax(matrix[i,:])\n",
    "    # after assigning the cluster labels, get the label predicted by the model using the cluster index assigned      \n",
    "    predicted = np.zeros(n_samples)\n",
    "    for i in range(1,n_samples):\n",
    "        predicted[i] = cluster_label[result[i]]\n",
    "    return predicted, cluster_label\n",
    "\n",
    "\n",
    "# get the no. of correctly classified samples\n",
    "def getAccuray(true_labels,predicted_labels,samples):\n",
    "    accuracy = 0.0;\n",
    "    for i in range(1,samples):\n",
    "        if(true_labels[i] == predicted_labels[i]):\n",
    "            accuracy +=1\n",
    "    return accuracy/samples\n",
    "def getImage(x):\n",
    "    img =  Image.fromarray(255 - (x.reshape(28, 28)).astype('uint8'))\n",
    "    plt.imshow(img,cmap='Greys_r')\n",
    "    plt.show()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "predictions,labels = getPredictions(result_w_s)\n",
    "getAccuray(true_labels,predictions,n_samples)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
